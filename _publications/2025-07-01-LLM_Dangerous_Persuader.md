---
title: "LLM can be a dangerous persuader: Empirical study of persuasion safety in large language models"
collection: publications
category: manuscripts
date: 2025-02-18
venue: 'COLM 2025'
paperurl: 'https://arxiv.org/abs/2504.10430'
citation: 'Minqian Liu, Zhiyang Xu, Xinyi Zhang, <strong>Heajun An</strong>, Sarvech Qadir, Qi Zhang, Pamela J. Wisniewski, Jin-Hee Cho, Sang Won Lee, Ruoxi Jia, and Lifu Huang (2025). "LLM Can Be a Dangerous Persuader: Empirical Study of Persuasion Safety in Large Language Models." <i>Proceedings of the Conference on Language Modeling (COLM 2025)</i>.'
---
